{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91fb31cb-e03e-42f1-9116-d11938890524",
   "metadata": {},
   "source": [
    "# a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c3340-0cb6-41de-9c5f-be5f0c17c90c",
   "metadata": {},
   "source": [
    "## Dataset Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e94ce54d-67e1-4c6b-b87f-e8cbe22b92a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f06feda-fc14-4f35-b815-0a85f85fb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd0c54b2-5c49-4da8-a013-fdc8eebe5669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36842</th>\n",
       "      <td>There's something going on in this film direct...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>First, I would like to admit that Chokher Bali...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>I imagine when Hitchcock scholars and experts ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8906</th>\n",
       "      <td>Strained and humorless (especially in light of...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48852</th>\n",
       "      <td>Saw this in the theater in '86 and fell out of...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15825</th>\n",
       "      <td>This movie is a quite fair adaptation of the P...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>I saw this movie last night and thought it was...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7245</th>\n",
       "      <td>The movie looked like a walk-through for \"Immo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19867</th>\n",
       "      <td>One-note comedy that probably sets modern day ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>*review may contain spoilers*&lt;br /&gt;&lt;br /&gt;predi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "36842  There's something going on in this film direct...  negative\n",
       "2948   First, I would like to admit that Chokher Bali...  negative\n",
       "4205   I imagine when Hitchcock scholars and experts ...  negative\n",
       "8906   Strained and humorless (especially in light of...  negative\n",
       "48852  Saw this in the theater in '86 and fell out of...  positive\n",
       "15825  This movie is a quite fair adaptation of the P...  positive\n",
       "287    I saw this movie last night and thought it was...  positive\n",
       "7245   The movie looked like a walk-through for \"Immo...  positive\n",
       "19867  One-note comedy that probably sets modern day ...  negative\n",
       "2138   *review may contain spoilers*<br /><br />predi...  negative"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(n= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0795e4-3be4-4b4d-ada1-2229ac95dcef",
   "metadata": {},
   "source": [
    "# b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b2f497-5476-43d8-a56c-3fd2b4969b63",
   "metadata": {},
   "source": [
    "## Preprocessing Steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "755818d7-2795-440f-8210-9743da0d25a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'] =  [1 if each == \"positive\" else 0 for each in data.sentiment]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88956365-ee8d-4ab1-ae04-c5312d0f8ea8",
   "metadata": {},
   "source": [
    "### loadin necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49df32e4-c319-4be7-82af-d9aac024e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31682c-f649-4ae9-8368-965f423663d8",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9b4a0c5-a311-4449-82b0-e122fc43c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b9f62d-7744-48d1-81e6-8b943a5f761f",
   "metadata": {},
   "source": [
    "### Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f939ccff-e6ad-42dd-b2f9-7f4e161c20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "data['review'] = data['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447750cf-f235-4f4b-a2be-dbe3733c4a8a",
   "metadata": {},
   "source": [
    "### lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a7f4ba3-dfa8-4459-b4b9-ae7fceac597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_words(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "data['review'] = data['review'].apply(lemmatize_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d2885-e4b6-4371-95ae-c1c7a7977dd6",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe013d1b-91f3-47f5-a685-8952a185d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(tokens):\n",
    "    return [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "data['review'] = data['review'].apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63deb800-a92a-4f6b-b236-21ff1119131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e79dc50d-1fce-435c-a136-5dc46fb39e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch 1 oz episod 'll hook ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product . &lt; br / &gt; &lt; br / &gt; film ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic 's famili littl boy ( jake ) think 's zo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei 's `` love time money '' visual ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movi right good job . n't creativ orig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot , bad dialogu , bad act , idiot direc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>cathol taught parochi elementari school nun , ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>'m go disagre previou comment side maltin one ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expect star trek movi high art , fan expec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      one review mention watch 1 oz episod 'll hook ...          1\n",
       "1      wonder littl product . < br / > < br / > film ...          1\n",
       "2      thought wonder way spend time hot summer weeke...          1\n",
       "3      basic 's famili littl boy ( jake ) think 's zo...          0\n",
       "4      petter mattei 's `` love time money '' visual ...          1\n",
       "...                                                  ...        ...\n",
       "49995  thought movi right good job . n't creativ orig...          1\n",
       "49996  bad plot , bad dialogu , bad act , idiot direc...          0\n",
       "49997  cathol taught parochi elementari school nun , ...          0\n",
       "49998  'm go disagre previou comment side maltin one ...          0\n",
       "49999  one expect star trek movi high art , fan expec...          0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f9117c-4b69-4756-9669-37aefb3e0c2b",
   "metadata": {},
   "source": [
    "# c."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bd4667-59f6-48b4-8dc4-dac93fc0e3ef",
   "metadata": {},
   "source": [
    "## CountVectorizer and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51472d01-9179-4e88-8807-0353571d397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_count = count_vectorizer.fit_transform(data['review'])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(data['review'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10fc171-bff0-4afb-8412-39ab6b3d81fa",
   "metadata": {},
   "source": [
    "# d."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1404eda2-2456-44ae-a057-2b328718214c",
   "metadata": {},
   "source": [
    "## splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad3f9e54-74e5-4188-bcb1-cc5dc776cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_tfidf[0:49999], data['sentiment'][0:49999], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_count[0:49999], data['sentiment'][0:49999], test_size=0.2, random_state=42)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled1 = scaler.fit_transform(X_train1)\n",
    "# X_test_scaled1 = scaler.transform(X_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3668044-438c-459a-b936-26d4ea719454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train_scaled2 = scaler.fit_transform(X_train2)\n",
    "# X_test_scaled2 = scaler.transform(X_test2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fb71c9-1a4f-4921-a8ef-415d0ef99073",
   "metadata": {},
   "source": [
    "# e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cf7bba-82d2-48fc-9b9a-d3f92584278d",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43308768-ff4f-4c2a-b6b4-bc4ce1d60f2d",
   "metadata": {},
   "source": [
    "### Naive Bayes with tf_idf model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61c215-fd9e-43fd-9862-9eb54b5c13e4",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "606e83e2-8df9-48bb-a9dd-93108823d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "nb_classifier_tfidf = MultinomialNB()\n",
    "nb_classifier_tfidf.fit(X_train1, y_train1)\n",
    "\n",
    "y_pred = nb_classifier_tfidf.predict(X_test1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a3553-0da5-4f8b-8189-46817c6cb03b",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca5cfa6e-0662-46d2-867f-bc8eafeb6e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TF_IDF vectorizer method: 0.8642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87      4969\n",
      "           1       0.88      0.85      0.86      5031\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['naive_bayes_model1.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy = accuracy_score(y_test1, y_pred)\n",
    "print(\"Accuracy for TF_IDF vectorizer method:\", accuracy)\n",
    "print(classification_report(y_test1, y_pred))\n",
    "\n",
    "joblib.dump(nb_classifier_tfidf, 'naive_bayes_model1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88540d4-7cd4-41ff-b472-22f294eeb051",
   "metadata": {},
   "source": [
    "### Naive Bayes with CountVectorizer model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551ff52c-9fe1-4550-ba7d-ce30508bbc7d",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74c2400a-5705-4c27-a11b-712561636877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "nb_classifier_count = MultinomialNB()\n",
    "nb_classifier_count.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = nb_classifier_count.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3281b3-b682-4b46-8b08-b58c6f392696",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "081ec171-faac-460c-bc7c-ee16eaa0eb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Count vectorizer method: 0.8567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      4969\n",
      "           1       0.87      0.84      0.85      5031\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['naive_bayes_model2.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy = accuracy_score(y_test2, y_pred)\n",
    "print(\"Accuracy for Count vectorizer method:\", accuracy)\n",
    "print(classification_report(y_test2, y_pred))\n",
    "\n",
    "joblib.dump(nb_classifier_count, 'naive_bayes_model2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328edf46-62b3-4de8-8414-3ac85755fdaf",
   "metadata": {},
   "source": [
    "# f."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52987d42-3d13-4920-828e-608b7be10983",
   "metadata": {},
   "source": [
    "### best models's prediction new review from the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a6a9254e-26fb-4446-b336-12a04a3adfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment for tf_idf vectorizer model : [0]\n",
      "Predicted sentiment for count vectorzer model: [0]\n"
     ]
    }
   ],
   "source": [
    "saved_model1 = joblib.load('naive_bayes_model1.pkl')\n",
    "saved_model2 = joblib.load('naive_bayes_model2.pkl')\n",
    "\n",
    "\n",
    "new_reivew_tfidf = X_tfidf[49999]\n",
    "new_reivew_count = X_count[49999]\n",
    "\n",
    "predicted_sentiment_tfidf = saved_model1.predict(new_reivew_tfidf)\n",
    "predicted_sentiment_count = saved_model2.predict(new_reivew_count)\n",
    "\n",
    "print(\"Predicted sentiment for tf_idf vectorizer model :\", predicted_sentiment_tfidf)\n",
    "print(\"Predicted sentiment for count vectorzer model:\", predicted_sentiment_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e843493b-3b65-4fd0-8b8c-1271bb9e1945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       one expect star trek movi high art , fan expec...\n",
       "sentiment                                                    0\n",
       "Name: 49999, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[49999]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1533e953-7aa6-4974-8fd4-320d463ae76f",
   "metadata": {},
   "source": [
    "### prediction  is correct for both tf_idf and CountVectorize methods "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
